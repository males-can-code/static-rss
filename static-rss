#!/usr/bin/python3

import os,sys
import feedparser
import inspect     # for Log
import re          # for Log
import hashlib
import sqlite3
import shutil
import subprocess
from time import strftime
from string import Template
from config import Config
from bs4 import BeautifulSoup

# TODO Limit downloaded entries per parse, if we don't limit it it will download the complete feed and entry history 

# TODO remove old entries after certain period, note that this will conflict with the above

# TODO maybe move menu to iframe and remove read/unread headline feature from entries
#      This way we can dramatically reduce the cpu load when generating html since there is
#      no need for regeneration if there is no possible change, only stuff is added
#      This btw also means that i have to move the pagelinks (maybe also in an iframe?)
#      Another solution may be that i can use reggex to change certain values (read/unread) in html files
#      so we don't have to regenerate the whole bunch but we still can retain this nice feature

# start page count at one

# TODO After podcasts also videocasts should be supported

# TODO Comments Comments Comments Comments

# TODO When a feed updates its entry I get a new copy, for some feeds this is really ennoying, eg. reddit

class Log(object):
    def __init__(self, log_file=False, level='debug', display=True, show='all', maxlength=15):
        self.log_file = log_file
        self.display = display
        self.show = show
        self.level = level
        self.maxlength = maxlength
        self.color_info = '\033[37m'         # white
        self.color_error = '\033[31m'
        self.color_debug = '\033[0m'
        self.color_warning = '\033[33m'
        self.color_reset = '\033[0m'

        self.color_message = '\033[35m'
        self.color_ip = '\033[1;32m'          # green
        self.color_inbound = '\033[1;36m'     # cyan
        self.color_outbound = '\033[1;31m'    # red
        self.color_listen = '\033[1;94m'      # blue
        self.color_connect = '\033[1;32m'     # green

        self.color_magenta = '\033[1;35m'
        self.color_green = '\033[1;32m'
        self.color_cyan = '\033[1;36m'
        self.color_red = '\033[1;31m'
        self.color_blue = '\033[1;94m'
        self.color_green = '\033[1;32m'
        self.color_white = '\033[0;37m'

        if self.log_file:
            try:
                with open(self.log_file) as f: pass
            except IOError as e:
                try:
                    FILE = open(self.log_file, 'w')
                    FILE.close()
                except IOError as e:
                    print('WARNING ... Couldn\'t create file \'%s\' Not writing logs!'%self.log_file)
                    return


    def create_message(self, msg_type, module, message, color):
        if self.level == 'error':
            if msg_type == 'debug' or msg_type == 'warning' or msg_type == 'info':
                return
        if self.level == 'warning':
            if msg_type =='debug' or msg_type == 'info':
                return
        if self.level == 'info':
            if msg_type == 'debug':
                return

        # custom syntax highlighting
        message = re.sub( '<<<', self.color_inbound + '<<<' + self.color_reset, message )
        message = re.sub( '>>>', self.color_outbound + '>>>' + self.color_reset, message )
        message = re.sub( 'LISTEN', self.color_listen + 'LISTEN' + self.color_reset, message )
        message = re.sub( 'CONNECT', self.color_connect + 'CONNECT' + self.color_reset, message )
        message = re.sub( 'Parsing:', self.color_blue + 'Parsing:' + self.color_white, message )
        message = re.sub( 'Inserting new entry:', self.color_green + 'Inserting new entry:' + self.color_reset, message )
        message = re.sub( 'Adding feed:', self.color_magenta + 'Adding feed:' + self.color_white, message )
        message = re.sub( 'Marking feed read:', self.color_red + 'Marking feed read:' + self.color_white, message )
        message = re.sub( 'Deleting entry:', self.color_red + 'Deleting entry:' + self.color_white, message )
        message = re.sub( 'Generating:', self.color_blue + 'Generating:' + self.color_white, message )

        address = re.findall( r'[0-9]+(?:\.[0-9]+){3}', message )
        if address:
            message = re.sub( r'[0-9]+(?:\.[0-9]+){3}', self.color_ip + address[0] + self.color_reset, message )

        timestamp = strftime("%H:%M:%S")
        module = module.ljust(self.maxlength)
        msg_type = msg_type.ljust(7)

        if self.display:
            #print(timestamp, color + msg_type.upper() + self.color_reset, module, color, message, self.color_reset)
            #print(timestamp, module, color + msg_type.upper(), message, self.color_reset)
            print(timestamp, module, color, message, self.color_reset)
        if self.log_file:
            FILE = open(self.log_file, 'a')
            FILE.write(timestamp + ' ' + msg_type + ' ' + module + ' ' + message + '\n')
            FILE.close()


    def info(self, message):
        color = self.color_info
        self.create_message('info', inspect.stack()[1][3], message, color)


    def debug(self, message):
        color = self.color_debug
        self.create_message('debug', inspect.stack()[1][3], message, color)


    def warning(self, message):
        color = self.color_warning
        self.create_message('warning', inspect.stack()[1][3], message, color)


    def error(self, message):
        color = self.color_error
        self.create_message('error', inspect.stack()[1][3], message, color)



class GenerateHTML(object):
    def copy_file(self, src, dest):
    # Copy a file
        try:
            shutil.copy(src, dest)
            return True
        except IOError as e:
            self.log.error('Failed to copy file: %s. Quitting...'%src)
            sys.exit()


    def copy_dir(self, src, dest):
    # Copy a dir
        try:
            self.remove_dir(dest)
            shutil.copytree(src,dest)
            return True
        except IOError as e:
            self.log.error('Failed to copy dir: %s. Quitting...'%src)
            sys.exit()


    def remove_dir(self, path):
    # TODO This needs work, the dir is not removed
    # Remove a tree
        if os.path.exists(path):
            try:
                shutil.rmtree(path)
            except:
                pass


    def check_dir(self, path):
    # Create dir if it doesn't exist, otherwise do nothing
        if not os.path.exists(path):
            try:
                os.makedirs(path)
                return True
            except IOError as e:
                self.log.error('Failed to create dir: %s. Quitting...'%path)
                sys.exit()
        else:
            return True


    def check_file(self, filename):
    # Check if file exists
        try:
            with open(filename) as f: pass
            return True
        except IOError as e:
            self.log.info('Failed to open file: %s'%filename)
            return False
        

    def get_file(self, filename):
    # Get file contents
        contents = []
        if self.check_file(filename):
            try:
                f = open(filename, 'r')
            except IOError as e:
                self.log.info('Failed to open file: %s'%filename)
                return False

            for line in f:
                #contents.append(self.sanitize(line))
                contents.append(line.rstrip())
            f.close()
            return contents
        else:
            return False
            

    def write_to_file(self, path, data):
    # (over)write data to file
        try:
            with open(path, 'w') as f:
                self.log.warning('writing file: %s'%path)
                f.write(data)
        except IOError:
            self.log.error('Failed to write to file: %s. Quitting...'%path)
            sys.exit()


    def parse_template(self, template, data):
    # Parse a template file, input is a dict: {data to be replaced : data to replace with}
    # Return is filled_template containing all the replaced lines
    # You can put switches in loops to turn certain elements on and off, really handy
    # Also it is possible to put other loops inside loops... dawg
        filled_template = ''
        if type(template) != list:
            template = self.get_file(template)
        loop_func = False
        switch = False

        if template:
            for line in template:
                # If '{{loop=' is encoutered in template keep on looping till {{endloop}} and 
                # send the lines to the function with the name 'loop_' + the stuff after '=' in template
                # Whatever returns from the loop function is added to the filled_template variable
                if '{{loop=' in line and not loop_func:
                    loop_lines = []
                    x,loop_func = line.split('=')
                    loop_func = loop_func.strip('}}')

                elif '{{endloop=%s}}'%loop_func in line:
                    if loop_func and len(loop_lines) > 0:
                        lines = getattr(self, 'loop_' + loop_func)(loop_lines, data)
                        filled_template = filled_template + lines
                    loop_func = False

                elif loop_func:
                    loop_lines.append(line)

                # If {{switch= is found the leading lines till {{endswitch=switch}} are written to switch_lines list
                # At {{endswitch=switch}} it will look for a key in self.switch that corresponds with the value after {{switch=
                # Value can be True or False
                elif '{{switch=' in line and not switch:
                    switch_lines = []
                    x,switch = line.split('=')
                    switch = switch.strip('}}')

                elif '{{endswitch=%s}}'%switch in line:
                    if switch and len(switch_lines) > 0:
                        if self.config.switch[switch]:
                            for switch_line in switch_lines:
                                for key in data.keys():
                                    if '$' + key in switch_line:
                                        switch_line = Template(switch_line).safe_substitute({key:data[key]})
                                filled_template = filled_template + switch_line + '\n'
                    switch = False

                elif switch:
                    switch_lines.append(line)

                else:
                    for key in data.keys():
                        if '$' + key in line:
                            line = Template(line).safe_substitute({key:data[key]})
                    filled_template = filled_template + line + '\n'
        return filled_template


    def loop_feed_list(self, lines, data):
    # Generate the left sidebar links
        filled_template = ''
        feed_url = {}
        last_group = ''
        for group in self.get_groups():

            # Get all feeds in specific group
            feeds = self.get_rows_by_value('feeds', 'feed_group',  group, order_by='feed_date_entered')
            for feed in feeds:
                data['group_title'] = group

                # Count unread entries per feed
                entries = self.get_rows_by_value('entries', 'entry_feed_hash', feed['feed_hash'], order_by='entry_date_published')
                unread_counter = 0
                for entry in entries:
                    if entry['entry_read'] == 'unread': unread_counter = unread_counter + 1

                data['feed_link'] = feed['feed_title'] 
                data['feed_url'] = self.config.domain + '/feeds/' + feed['feed_hash']

                if unread_counter > 0:
                    data['counter'] = '[' + str(unread_counter) + ']'
                    data['feed_read'] = 'unread'
                else:
                    data['counter'] = ''
                    data['feed_read'] = 'read'

                # So i heard you like loops ...
                # Parse template with switches again
                # TODO I really don't like this evil construction but oh well...
                if feed == feeds[0] and feed == feeds[-1]:
                    # The only feed in group, display all
                    self.config.switch['feed_list_title'] = True
                    self.config.switch['feed_list_link'] = True
                    self.config.switch['feed_list_close'] = True
                elif feed == feeds[0]:
                    # The first feed of a new group, display title and link
                    self.config.switch['feed_list_title'] = True
                    self.config.switch['feed_list_link'] = True
                    self.config.switch['feed_list_close'] = False
                elif feed == feeds[-1]:
                    # The first feed of a new group, display link and group close (eg: </div>)
                    self.config.switch['feed_list_title'] = False
                    self.config.switch['feed_list_link'] = True
                    self.config.switch['feed_list_close'] = True
                else:
                    # Display only the link
                    self.config.switch['feed_list_title'] = False
                    self.config.switch['feed_list_link'] = True
                    self.config.switch['feed_list_close'] = False

                group_filled = self.parse_template(lines, data)
                filled_template = filled_template + group_filled

        return filled_template


    def loop_page(self, lines, data):
        filled_template = ''
        filled_template = filled_template + self.parse_template(self.config.path_template_page, data)
        return filled_template


    def loop_entries(self, lines, feed):
    # Generate a page with entries (posts)
        filled_template = ''
        entries = self.get_rows_by_value('entries', 'entry_feed_hash', feed['feed_hash'], order_by='entry_date_published') 
        for entry in entries:
            entry['links_target'] = self.config.links_target          # Open links in self or blank
            if entry['entry_hash'] in feed['page']:
                filled_template = filled_template + self.parse_template(lines, entry)
        return filled_template


    def loop_media(self, lines, entry):
        # if there are multiple media files attached to entry loop the code for every file
        # Return nothing if there are no media files (so no need for a switch)
        filled_template = ''
        if entry['entry_media']:
            medias = entry['entry_media'].split(',')
            for media in medias:
                if media:
                    entry['entry_media'] = media
                    filled_template = filled_template + self.parse_template(lines, entry)
        return filled_template


    def calculate_pages(self, feed):
    # Calculate on how many pages the entries will be spread out
        pages = []
        entry_hash_list = []
        c = 1
        entries = self.get_rows_by_value('entries', 'entry_feed_hash', feed['feed_hash'], order_by='entry_date_published') 
        for entry in entries:
            entry_hash_list.append(entry['entry_hash'])
            if len(entry_hash_list) >= self.config.entries_per_page or c == len(entries):
                pages.append(entry_hash_list)
                entry_hash_list = []
            c = c + 1
        return pages


    def generate_next_link(self, pages, feed, cur_page):
    # Generate the link to the next page (right from the page links)
        self.config.switch['next'] = True
        if cur_page == 1:
            self.config.switch['next'] = False
        elif cur_page <= len(pages):
            return 'page_' + str(cur_page - 1) + '.html'


    def generate_menu(self, template): 
        # Generate menu
        self.log.info('Generating: menu.html: %s'%self.config.path_export_html + '/menu.html')
        filled_menu_template = self.parse_template(self.config.path_template_menu, template)
        self.write_to_file(self.config.path_export_html + '/menu.html', filled_menu_template)


    def generate_index(self, feed_hash, template): 
        # Generate index.html
        self.log.info('Generating: index.html: %s'%self.config.path_export_html + '/index.html')
        filled_index_template = self.parse_template(self.config.path_template_index, template)
        self.write_to_file(self.config.path_export_html + '/index.html', filled_index_template)


    def gen_init(self, feeds, del_dir=True):
    # Create/remove/copy dirs and files
        if del_dir: self.remove_dir(self.config.path_export_html)
        self.check_dir(self.config.path_export_html)
        self.copy_dir(self.config.path_css, self.config.path_export_html + '/css')
        self.copy_dir(self.config.path_php, self.config.path_export_html + '/php')
        self.copy_dir(self.config.path_js, self.config.path_export_html + '/js')
        self.copy_file(self.config.path_favicon, self.config.path_export_html)
        for feed in feeds: # Create all feed dirs which will store the entries
            self.check_dir(self.config.path_export_html + '/feeds/' + feed['feed_hash'])


    def generate_HTML(self, del_dir=False, partial=True, feeds_gen='all'):
    # The main method that calls the other method in class and eventually generates the HTML
        self.log.info('Generating HTML')
        feeds = self.get_table('feeds')                        # Get a list of dicts containing information about a feed
        if del_dir == True: self.gen_init(feeds, del_dir=True) # Sometimes we don't wanna delete the export dir but just overwrite because  
        else: self.gen_init(feeds, del_dir=False)              # there will be a (short) moment where you will get a 404 when a file is missing

        template = {}               # feed_template dict contains main content for the 'feed.html' template 
        template['auto_refresh']    = self.config.switch['auto_refresh']
        template['domain']          = self.config.domain
        template['favicon']         = self.config.domain + '/favicon.ico'
        template['css']             = self.config.domain + '/css/' + os.path.basename(self.config.path_stylesheet)

        self.generate_menu(template)                           # Generate menu
        self.generate_index(feeds[0]['feed_hash'], template)   # Generate index.html

        for feed in feeds:                                                  # Create html pages for every page of every feed
            if feed['feed_hash'] in feeds_gen or feeds_gen == 'all':        # only generate feed if it has new messages
                self.log.info('Generating: %s'%feed['feed_title'])

                template['pages']      = self.calculate_pages(feed)         # Calculate in how many pages the entries fit
                template['feed_title'] = feed['feed_title']                 # Title is same for every page in feed
                template['feed_hash']  = feed['feed_hash']

                cur_page = len(template['pages'])
                for page in template['pages'][0:self.config.max_pages]:

                    # If partial is set, only regenerate the pages with unread entries (after parsing the newest) in it
                    contains_unread = False
                    if partial:
                        if self.check_in_row_by_value('entries', 'entry_read', 'unread', "entry_hash", page):
                            contains_unread = True
                        
                    if contains_unread or not partial:
                        template['page']      = page
                        template['page_next'] = self.generate_next_link(template['pages'], feed, cur_page)
                        template['go_back']   = '%s/feeds/%s' %(self.config.domain, feed['feed_hash'])

                        # Parse the template and write to file
                        if cur_page == len(template['pages']):
                            # Generate the highest (newest) page as index.html in feed dir (this file will be linked to from menu)
                            filled_template = self.parse_template(self.config.path_template_feed, template)
                            self.write_to_file('%s/feeds/%s/index.html'%(self.config.path_export_html, feed['feed_hash']), filled_template)
                        else:
                            filled_template = self.parse_template(self.config.path_template_page, template)
                            self.write_to_file('%s/feeds/%s/page_%s.html'%(self.config.path_export_html, feed['feed_hash'], str(cur_page)), filled_template)
                        cur_page = cur_page - 1

 

class Database(object):
    def create_tables(self): 
    # Create database and tables
        db = sqlite3.connect(self.config.path_db)
        db.execute("create table if not exists feeds (feed_hash         text unique  ,"
                                                     "feed_title        text         ,"
                                                     "feed_date_entered int          ,"
                                                     "feed_url          text         ,"
                                                     "feed_icon_url     text         ,"
                                                     "feed_last_updated text         ,"
                                                     "feed_group        text         )")

        db.execute("create table if not exists entries (entry_hash           text unique  ,"
                                                       "entry_content        text         ,"
                                                       "entry_url            text         ,"
                                                       "entry_media          text         ,"
                                                       "entry_title          text         ,"
                                                       "entry_read           text         ,"
                                                       "entry_date_published text         ,"
                                                       "entry_feed_hash      text         )")
        db.commit()
        db.close()


    def get_table(self, table, order_by='ROWID'):
    # Spits out the complete table into a list of dictionaries
        db = sqlite3.connect(self.config.path_db)
        rows = []
        cols = []
        table_export = []

        for row in db.execute('select * from %s order by %s'%(table,order_by)):
            rows.append(row)

        for row in db.execute('PRAGMA table_info(%s)'%table):
            cols.append(row[1])

        for row in rows:
            row_export = {}
            for x in range(0,len(cols)):
                row_export[cols[x]] = row[x]
            table_export.append(row_export)

        db.close()
        return table_export


    def get_rows_by_value(self, table, col, value, order_by, limit='all'):
    # Get a list of all rows containing a value
        db = sqlite3.connect(self.config.path_db)
        rows = []
        cols = []
        rows_export = []
        if limit == 'all':
            for row in db.execute('select * from %s where "%s" is "%s" order by "%s" desc'%(table, col, value, order_by)):
                rows.append(row)
        else:
            for row in db.execute('select * from %s where "%s" is "%s" order by "%s" desc limit %s'%(table, col, value, order_by, limit)):
                rows.append(row)

        for row in db.execute('PRAGMA table_info(%s)'%table):
            cols.append(row[1])

        for row in rows:
            row_export = {}
            for x in range(0,len(cols)):
                row_export[cols[x]] = row[x]
            rows_export.append(row_export)

        db.close()
        return rows_export


    def insert_row(self, table, row):
    # Insert a row
        db = sqlite3.connect(self.config.path_db)
        values = []
        for key in row:
            values.append(row[key])
        keys = ','.join(row.keys())
        query = 'INSERT INTO %s(%s) VALUES(%s)'%(table, keys, ','.join(['?'] * len(row)))
        try:
            db.execute(query,values)
            db.commit()
            db.close()
        except sqlite3.Error as e:
            self.log.error('Failed to insert row: %s'%e.args[0])
            db.close()


    def update_row(self, table, col1, value1, col2, value2):
    # Update one or more rows, you can also feed value2 as a list
        db = sqlite3.connect(self.config.path_db)
        if type(value2) == list:
            tmp_value2 = ''
            for v in value2:
                tmp_value2 = tmp_value2 + ',\'' + v + '\''
            value2 = tmp_value2.lstrip(',')
        else:
            value2 = '\'' + value2 + '\''
        db.execute('update %s set "%s" = "%s" where "%s" in (%s)'%(str(table), str(col1), str(value1), str(col2), str(value2)))
        db.commit()
        db.close()


    def delete_older_than(self, table, days):
        db = sqlite3.connect(self.config.path_db)
        for row in db.execute('delete from %s where entry_date_published <= date("now()","-2 day")'%(table)):
            self.log.info('Deleting entry: %s'%row['entry_title'])
        try:
            db.commit()
            db.close()
        except sqlite3.Error as e:
            self.log.error('Failed to delete row: %s'%e.args[0])
            db.close()


    def delete_row_by_value(self, table, col, value):
        db = sqlite3.connect(self.config.path_db)
        db.execute('delete from %s where "%s" = "%s"'%(table,col,value))
        try:
            db.commit()
            db.close()
        except sqlite3.Error as e:
            self.log.error('Failed to delete row: %s'%e.args[0])
            db.close()


    def check_in_table(self, table, col, value):
    # Return True/False if a value exists in table
        db = sqlite3.connect(self.config.path_db)
        for data in db.execute('select * from "%s" where "%s" = "%s"'%(str(table),str(col),str(value))):
            if data:
                db.close()
                return True
        db.close()
        return False


    def check_in_row_by_value(self, table, col1, value1, col2, value2):
    # Return True/False if a value exists in table
        db = sqlite3.connect(self.config.path_db)
        if type(value2) == list:
            tmp_value2 = ''
            for v in value2:
                tmp_value2 = tmp_value2 + ',\'' + v + '\''
            value2 = tmp_value2.lstrip(',')
        else:
            value2 = '\'' + value2 + '\''
        for data in db.execute('select * from "%s" where "%s" = "%s" and "%s" in (%s)'%(str(table),str(col1),str(value1),str(col2),str(value2))):
            if data:
                db.close()
                return True
        db.close()
        return False
        


class RSS(Database, GenerateHTML):
    def __init__(self):
        self.log = Log()
        self.config = Config()


    def get_timestamp(self, human_readable=True):
        if human_readable:
            timestamp = strftime("%Y-%m-%d %H:%M:%S")
        else:
            timestamp = strftime("%Y%m%d%H%M%S")
        return timestamp


    def get_hash(self, data):
    # Clean up var and create a hash of data
        data = self.sanitize(data)
        data = self.encode(data)
        hashed = hashlib.sha224(data).hexdigest()
        return hashed


    def get_groups(self):
    # Get a list of groups that contain feeds
        group_list = []
        feeds = self.get_table('feeds')
        for feed in feeds:
            if feed['feed_group'] not in group_list:
                group_list.append(feed['feed_group'])
        return group_list


    def parse_feed(self, url):
    # Parse feed with feedparser module or return False
        self.log.info('Parsing: %s'%url)
        parsed_feed = feedparser.parse(url)
        if len(parsed_feed.feed) < 1:
            self.log.error('Failed to import feed: %s'%url)
            return False
        else:
            return parsed_feed


    def parse_feeds(self):
    # Parse all feeds, calls parse_feed()
        feeds_gen = []
        feeds = self.get_table('feeds')
        for feed in feeds:
            parsed_feed = self.parse_feed(feed['feed_url'])
            if parsed_feed:
                for entry in parsed_feed.entries:
                    if not self.check_in_table('entries', 'entry_hash', str(self.get_hash(entry['title'] + str(self.clean_HTML(entry['summary']))))):
                        self.add_entry(entry, feed['feed_url'])
                        # Add feed_hash from feeds with unread messages to feeds_gen so we know which html should be regenerated
                        if feed['feed_hash'] not in feeds_gen:
                            feeds_gen.append(feed['feed_hash'])
        return feeds_gen


    def sanitize(self, var):
    # Strip file from blanks and newlines
        var = var.strip()
        return var


    def encode(self, data):
    # Convert var to utf-8
        try:
            data = data.encode('utf-8')
            return data
        except:
            self.log.warning('Failed to encode data, data is already urf-8?')


    def add_feed(self, feed):
    # Gather information to add feed to database, feed is a list [url,group]
        feed_insert = {}
        parsed_feed = self.parse_feed(feed[0])
        if len(parsed_feed.version) != 0:
            if parsed_feed:
                feed_insert['feed_hash'] = str(self.get_hash(feed[0]))
                feed_insert['feed_date_entered'] = str(self.get_timestamp())
                feed_insert['feed_url'] = str(feed[0])
                feed_insert['feed_icon_url'] = 'None'
                feed_insert['feed_last_updated'] = 'None'
                feed_insert['feed_group'] = feed[1]

                if 'title' in parsed_feed.feed.keys():
                    feed_insert['feed_title'] = str(parsed_feed.feed['title'])
                else:
                    feed_insert['feed_title'] = str(feed[0])

                self.log.info('Adding feed: %s'%feed[0])
                self.insert_row('feeds', feed_insert)
        else:
            self.log.error('Url is not a feed')


    def clean_HTML(self, content):
        soup = BeautifulSoup(content)

        for tag in self.config.invalid_tags: 
            for match in soup.findAll(tag):
                        match.replaceWithChildren()

        for tag in soup():
            for attribute in self.config.invalid_attr:
                del tag[attribute]

        return soup


    def add_entry(self, entry, url):
    # Gather information to add entry (post) to database
        self.log.info('Inserting new entry: %s'%entry['title'])
        entry_insert = {}

        # Try to get title otherwise insert link or unknown
        try:
            entry_insert['entry_title']           = str(entry['title'])
        except:
            try:
                entry_insert['entry_title']           = str(entry['link'])
                self.log.warning('Failed to find title, using \'url\'')
            except:
                entry_insert['entry_title']           = 'unknown'
                self.log.warning('Failed to find title, using \'unknown\'')

        entry_insert['entry_content']         = str(self.clean_HTML(entry['summary']))
        entry_insert['entry_hash']            = str(self.get_hash(entry_insert['entry_title'] + entry_insert['entry_content']))
        entry_insert['entry_read']            = 'unread'
        #entry_insert['entry_date_entered']    = str(self.get_timestamp(human_readable=False))
        entry_insert['entry_feed_hash']       = str(self.get_hash(url))

        # Try to get url otherwise insert unknown
        try:
            entry_insert['entry_url']       = str(entry['link'])
        except:
            entry_insert['entry_url']       = 'unknown'
            self.log.warning('Failed to find url for entry, using \'unknown\'')

        # Try to get a date if available otherwise insert timestamp
        try:
            p = entry.published_parsed
        except:
            try:
                p = entry.updated_parsed
            except:
                try:
                    p = entry.created_parsed
                except:
                    p = False

        if p:
            # The date as returned from feedparser is in form: 2013-1-12, and must be 2013-01-12
            date = []
            for x in p:
                date.append(str(x).rjust(2,'0'))
            entry_insert['entry_date_published'] = str('%s-%s-%s %s:%s:%s'%(date[0],date[1],date[2],date[3],date[4],date[5]))
        else:
            entry_insert['entry_date_published'] = str(self.get_timestamp())
            self.log.warning('Failed to find a date, using timestamp')

        # Find audio in entry eg. in case of podcast and add it to entry_insert as a comma separated list
        entry_insert['entry_media'] = ''
        if len(entry.enclosures) > 0:
            for enclosure in entry.enclosures:
                if 'audio' in enclosure['type']:
                    entry_insert['entry_media'] = entry_insert['entry_media'] + enclosure['href'] + ','
        self.insert_row('entries', entry_insert)


    def del_feed(self, feed_hash):
        self.log.info('Deleting feed: %s'%feed_hash)
        if self.check_in_table('entries', 'entry_feed_hash',feed_hash):
            # First delete entries belonging to feed
            self.delete_row_by_value('entries', 'entry_feed_hash', feed_hash)
        else:
            self.log.error('Failed to remove entries, no entries belong to feed with hash: %s'%feed_hash)
        if self.check_in_table('feeds','feed_hash', feed_hash):
            # Delete feed
            self.delete_row_by_value('feeds', 'feed_hash', feed_hash)
        else:
            self.log.error('Failed to remove feed, feed doesn\'t exist')


    def mark_read(self, feed_hash):
    # Mark a feed as read
        self.log.info('Marking feed read: %s'%feed_hash)
        self.update_row('entries', 'entry_read', 'read', 'entry_feed_hash', feed_hash)


    def mark_all_read(self):
    # Mark all feeds as read, and return a list of changed feeds so they can be regenerated
        feeds_mark_read = []
        entries = self.get_rows_by_value('entries', 'entry_read', 'unread', order_by='entry_date_published')
        for entry in entries:
            feeds_mark_read.append(entry['entry_feed_hash'])
        feeds_mark_read = list(set(feeds_mark_read))
        for h in feeds_mark_read:
            self.log.info('Marking feed read: %s'%h)
        self.update_row('entries', 'entry_read', 'read', 'entry_feed_hash', feeds_mark_read)
        return feeds_mark_read


    def check_ttl(self):
        if self.config.entry_ttl:
            self.log.info('Checking TTL')
            self.delete_older_than('entries',self.config.entry_ttl)


    def init(self):
    # Create tables, input feeds from config file in table
    # TODO are there feeds? what will happen if not?
        self.check_dir(os.path.dirname(self.config.path_db))
        self.create_tables()
        self.check_ttl()

        if len(self.config.feeds) >= 1:
            for feed in self.config.feeds:
                if not self.check_in_table('feeds', 'feed_hash', str(self.get_hash(feed[0]))):
                    self.add_feed(feed)
        else:
            self.log.error('No feeds in config file')


    def usage(self):
    # Display help
        print('static-rss - An RSS reader that outputs static HTML')
        print('Syntax: static-rss [OPTION]...')
        print()
        print('Options:')
        print('    -p, --parse-feeds              -parse feeds')
        print('    -g, --gen-html                 -generate HTML')
        print('        --mark-read=<hash>         -mark feed as read')
        print('    -M, --mark-all-read            -mark all feeds as read')
        print('        --subscribe=<url>          -subscribe to feed')
        print('        --del_feed=<hash>          -delete feed and all its entries')
        print()
        print('    -h, --help                     -this text')
                                                                 

    def run(self):
        if len(sys.argv) <= 1:
            self.usage()
            sys.exit()


        if '-h' in sys.argv or '--help' in sys.argv:
            self.usage()
            sys.exit()

        if len(sys.argv) >= 2:
            self.init()

            for arg in sys.argv:
                if '--subscribe=' in arg:
                    x,url = arg.split('=') 
                    for arg in sys.argv:
                        if '--group=' in arg:
                            x,group = arg.split('=') 
                            if len(url) > 0 and len(group) > 0:
                                self.add_feed([url, group])
                            else:
                                self.log.error('Failed to enter url... Quitting...')
                                sys.exit()
                    
            if '--parse-feeds' in sys.argv or '-p' in sys.argv:
                feeds_gen = self.parse_feeds()
                self.generate_HTML(del_dir=False, partial=True, feeds_gen=feeds_gen)

            if '--mark-all-read' in sys.argv or '-M' in sys.argv:
                marked_read = self.mark_all_read()
                self.generate_HTML(del_dir=False, partial=False, feeds_gen=marked_read)

            for arg in sys.argv:
                if '--mark-read=' in arg:
                    x,hash = arg.split('=') 
                    self.mark_read(hash)
                    self.generate_HTML(del_dir=False, partial=False, feeds_gen=[hash])

                if '--del-feed=' in arg:
                    x,hash = arg.split('=') 
                    self.del_feed(hash)
                    self.generate_HTML(del_dir=False, feeds_gen=[])

            if '--gen-html' in sys.argv or '-g' in sys.argv:
                self.generate_HTML()
                sys.exit()

            if '-G' in sys.argv:
                self.generate_HTML(del_dir=True, partial=False, feeds_gen='all')
                sys.exit()


app = RSS()
app.run()
